{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aryCtguFN9e3",
        "outputId": "f991b56a-06d2-46ea-a8d8-22d100e0f6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.32.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (0.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torchtext==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchtext==0.6.0) (3.0.2)\n",
            "disaster_data.csv.1 100%[===================>] 222.42K  --.-KB/s    in 0.002s  \n"
          ]
        }
      ],
      "source": [
        "#@title Run this to setup the environment and load the data\n",
        "import re\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install torchtext==0.6.0\n",
        "from torchtext.vocab import GloVe\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Disaster%20Relief/disaster_data.csv'\n",
        "dataset_path = './disaster_data.csv'\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import requests, io, zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix36mXERDGRj"
      },
      "outputs": [],
      "source": [
        "#@title If the previous cell fails to load data, use this cell\n",
        "import re\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchtext.vocab import GloVe\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import requests, io, zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFnXuHYGRxXN"
      },
      "source": [
        "## Instructor-Led Discussion: Modeling the Meaning of Websites using Word Vectors\n",
        "\n",
        "A shortcoming of our bag-of-words approach is that it only looks at the counts of words in each tweet. What if we had some way of understanding the meaning of words keeping the ordering in mind?\n",
        "\n",
        "The idea of computationally extracting meaning from words is central to word vectors, which have become a cornerstone of modern deep learning on text. Word vectors are a mapping from words to vectors such that words that have similar meaning have similar word vectors.\n",
        "\n",
        "For example, the words \"good\" and \"great\" have similar word vectors, and the words \"good\" and \"planet\" have different word vectors. Thus, word vectors provide us a way to account for the meanings of words with our machine learning models.\n",
        "\n",
        "We will look at GLoVe Embeddings in this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbW0_pxGhSKM"
      },
      "source": [
        "In this notebook we'll be:\n",
        "*   Exploring Word Similarities\n",
        "*   Visualizing Word Vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdgTrYyT0Gc"
      },
      "source": [
        "###Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KTWiw50OxEo"
      },
      "outputs": [],
      "source": [
        "# Load the data.\n",
        "disaster_tweets = pd.read_csv('disaster_data.csv',encoding =\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "wBxY2vr4RkVn",
        "outputId": "23a7dfb1-e712-4dfa-a866-16c176c3dabe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  tweet_id  \\\n",
              "0   ca9e24c8-396d-4502-8b45-18895df5333e_0   \n",
              "1             twitter_resource_tweets_1692   \n",
              "2     625b46e2-0b81-41ea-826e-4535fe9b39b8   \n",
              "3             twitter_resource_tweets_1699   \n",
              "4     c3bfea72-d377-445c-b4b8-e8ebca0e7fbb   \n",
              "5     ef6f7061-634d-4357-b4b6-920a4d23a959   \n",
              "6                 twitter_need_tweets_1572   \n",
              "7                 twitter_need_tweets_1571   \n",
              "8               twitter_random_tweets_4486   \n",
              "9     ac4a47e8-1031-479e-b26b-970bc735eb4d   \n",
              "10    4c63a84a-e61f-46e4-907e-e4a67c6f12b6   \n",
              "11    1caaf3d2-8800-425e-b428-8c22645b85ef   \n",
              "12    dc58d173-48c9-4482-81d6-615f8f34d279   \n",
              "13              twitter_random_tweets_2956   \n",
              "14    a9e793f8-b33f-4570-baaa-57d2ef023323   \n",
              "15    1369e2e7-4ae3-439c-9d95-631f4058d6c1   \n",
              "16  8adf9ef0-3b57-45d7-937d-6c104a2ab1e7_0   \n",
              "17    66d0729c-2b44-4ca5-ae2d-ea489ebef4e1   \n",
              "18    50d97b22-8496-4060-955f-5b37b9d58b4b   \n",
              "19    5a1590c5-86b5-4cd5-830d-e9f352f24946   \n",
              "20    985a826d-ac19-400b-a1d0-3bd5b6aa07ac   \n",
              "21                twitter_need_tweets_3366   \n",
              "22    09c2b4fc-babc-4ea4-81ae-5260e662afe5   \n",
              "23    a902512b-eec4-4efe-858d-1deb74be13a3   \n",
              "24              twitter_random_tweets_1192   \n",
              "25    7e264c5e-9a96-4e48-9790-7bd55e63d6ff   \n",
              "26    b22d82aa-29f9-49a4-9c91-ef9920976aaa   \n",
              "27    9fb74b4c-365c-482f-9fe8-3369f1552aa7   \n",
              "28    0b694ef1-3b4d-4b22-bea2-fab0667a1741   \n",
              "29            twitter_resource_tweets_1852   \n",
              "\n",
              "                                                 text category  \\\n",
              "0   Donations of batteries, flashlights, and clean...   Energy   \n",
              "1   I want hurricane Sandy to cone so I can be stu...      NaN   \n",
              "2   Hi, I can help prepare food, serve food, offer...     Food   \n",
              "3                           I cant believe Sandy.....      NaN   \n",
              "4   I have children and adult clothes including ja...    Water   \n",
              "5   I have two small children but we would like to...     Food   \n",
              "6   Supermarket had no food #scary #hurricanesandy...      NaN   \n",
              "7   spooky: the total lack of power from 34th st -...   Energy   \n",
              "8   Will these storms ever give L.I. a break? Firs...   Energy   \n",
              "9   We're very concerned about our 90-year old gra...   Energy   \n",
              "10  I am happy to serve food or help with taking f...     Food   \n",
              "11  psychological services (phd in psychology); ca...     Food   \n",
              "12                                    2 jugs of water    Water   \n",
              "13  Enjoying life in the dark.... (@ Hurricane San...   Energy   \n",
              "14  I am a chef and offer my services at a food ba...     Food   \n",
              "15      Can bring groceries and toiletries as needed.     Food   \n",
              "16  ************************. (Needs confirmation ...     Food   \n",
              "17  My cousin and his wife are stuck. There is no ...   Energy   \n",
              "18  I have non-perishable food, men's and women's ...     Food   \n",
              "19                        Baby formula and other food     Food   \n",
              "20  I am cpr and first aid certified. I have exper...  Medical   \n",
              "21          We just lost power on 20th street. #sandy   Energy   \n",
              "22                          6 cases of bottled water.    Water   \n",
              "23  I have gently used clothing, like new coats, n...     Food   \n",
              "24  There is no way in or out of Manhattan right n...      NaN   \n",
              "25                          Food Delivery/Preparation     Food   \n",
              "26  I can donate clothing, hot meals, non-perishab...     Food   \n",
              "27  My apartment was flooded knee deep. The water ...    Water   \n",
              "28                                        Supply food     Food   \n",
              "29  @austeremoi It's always good to weather the st...      NaN   \n",
              "\n",
              "   need_or_resource  \n",
              "0              need  \n",
              "1               NaN  \n",
              "2          resource  \n",
              "3               NaN  \n",
              "4          resource  \n",
              "5          resource  \n",
              "6               NaN  \n",
              "7              need  \n",
              "8              need  \n",
              "9              need  \n",
              "10         resource  \n",
              "11         resource  \n",
              "12         resource  \n",
              "13             need  \n",
              "14         resource  \n",
              "15         resource  \n",
              "16             need  \n",
              "17             need  \n",
              "18         resource  \n",
              "19         resource  \n",
              "20         resource  \n",
              "21             need  \n",
              "22         resource  \n",
              "23         resource  \n",
              "24              NaN  \n",
              "25         resource  \n",
              "26         resource  \n",
              "27             need  \n",
              "28         resource  \n",
              "29              NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7c4e6c2-4694-4197-9504-ff5519439cd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>need_or_resource</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ca9e24c8-396d-4502-8b45-18895df5333e_0</td>\n",
              "      <td>Donations of batteries, flashlights, and clean...</td>\n",
              "      <td>Energy</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_resource_tweets_1692</td>\n",
              "      <td>I want hurricane Sandy to cone so I can be stu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>625b46e2-0b81-41ea-826e-4535fe9b39b8</td>\n",
              "      <td>Hi, I can help prepare food, serve food, offer...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_resource_tweets_1699</td>\n",
              "      <td>I cant believe Sandy.....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c3bfea72-d377-445c-b4b8-e8ebca0e7fbb</td>\n",
              "      <td>I have children and adult clothes including ja...</td>\n",
              "      <td>Water</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ef6f7061-634d-4357-b4b6-920a4d23a959</td>\n",
              "      <td>I have two small children but we would like to...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>twitter_need_tweets_1572</td>\n",
              "      <td>Supermarket had no food #scary #hurricanesandy...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>twitter_need_tweets_1571</td>\n",
              "      <td>spooky: the total lack of power from 34th st -...</td>\n",
              "      <td>Energy</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>twitter_random_tweets_4486</td>\n",
              "      <td>Will these storms ever give L.I. a break? Firs...</td>\n",
              "      <td>Energy</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ac4a47e8-1031-479e-b26b-970bc735eb4d</td>\n",
              "      <td>We're very concerned about our 90-year old gra...</td>\n",
              "      <td>Energy</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4c63a84a-e61f-46e4-907e-e4a67c6f12b6</td>\n",
              "      <td>I am happy to serve food or help with taking f...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1caaf3d2-8800-425e-b428-8c22645b85ef</td>\n",
              "      <td>psychological services (phd in psychology); ca...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>dc58d173-48c9-4482-81d6-615f8f34d279</td>\n",
              "      <td>2 jugs of water</td>\n",
              "      <td>Water</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>twitter_random_tweets_2956</td>\n",
              "      <td>Enjoying life in the dark.... (@ Hurricane San...</td>\n",
              "      <td>Energy</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>a9e793f8-b33f-4570-baaa-57d2ef023323</td>\n",
              "      <td>I am a chef and offer my services at a food ba...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1369e2e7-4ae3-439c-9d95-631f4058d6c1</td>\n",
              "      <td>Can bring groceries and toiletries as needed.</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8adf9ef0-3b57-45d7-937d-6c104a2ab1e7_0</td>\n",
              "      <td>************************. (Needs confirmation ...</td>\n",
              "      <td>Food</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>66d0729c-2b44-4ca5-ae2d-ea489ebef4e1</td>\n",
              "      <td>My cousin and his wife are stuck. There is no ...</td>\n",
              "      <td>Energy</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>50d97b22-8496-4060-955f-5b37b9d58b4b</td>\n",
              "      <td>I have non-perishable food, men's and women's ...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5a1590c5-86b5-4cd5-830d-e9f352f24946</td>\n",
              "      <td>Baby formula and other food</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>985a826d-ac19-400b-a1d0-3bd5b6aa07ac</td>\n",
              "      <td>I am cpr and first aid certified. I have exper...</td>\n",
              "      <td>Medical</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>twitter_need_tweets_3366</td>\n",
              "      <td>We just lost power on 20th street. #sandy</td>\n",
              "      <td>Energy</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>09c2b4fc-babc-4ea4-81ae-5260e662afe5</td>\n",
              "      <td>6 cases of bottled water.</td>\n",
              "      <td>Water</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>a902512b-eec4-4efe-858d-1deb74be13a3</td>\n",
              "      <td>I have gently used clothing, like new coats, n...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>twitter_random_tweets_1192</td>\n",
              "      <td>There is no way in or out of Manhattan right n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>7e264c5e-9a96-4e48-9790-7bd55e63d6ff</td>\n",
              "      <td>Food Delivery/Preparation</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>b22d82aa-29f9-49a4-9c91-ef9920976aaa</td>\n",
              "      <td>I can donate clothing, hot meals, non-perishab...</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>9fb74b4c-365c-482f-9fe8-3369f1552aa7</td>\n",
              "      <td>My apartment was flooded knee deep. The water ...</td>\n",
              "      <td>Water</td>\n",
              "      <td>need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0b694ef1-3b4d-4b22-bea2-fab0667a1741</td>\n",
              "      <td>Supply food</td>\n",
              "      <td>Food</td>\n",
              "      <td>resource</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>twitter_resource_tweets_1852</td>\n",
              "      <td>@austeremoi It's always good to weather the st...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7c4e6c2-4694-4197-9504-ff5519439cd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7c4e6c2-4694-4197-9504-ff5519439cd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7c4e6c2-4694-4197-9504-ff5519439cd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-74cdbe81-3665-4a8b-984f-4001829828da\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74cdbe81-3665-4a8b-984f-4001829828da')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-74cdbe81-3665-4a8b-984f-4001829828da button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "disaster_tweets",
              "summary": "{\n  \"name\": \"disaster_tweets\",\n  \"rows\": 1358,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          \"2c76c16c-d0ca-4b6e-8f77-4062982f673a\",\n          \"twitter_random_tweets_5120\",\n          \"0d0764be-7407-4723-a155-e6de18bc9761\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          \"baby supplies hygiene products non perishable foods\",\n          \"Local fame has been achieved.... HAHAHA the local representative of hurricane sandy right here...\",\n          \"I heard that you are accepting prepared food. I am happy to cook and bring food.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Food\",\n          \"Medical\",\n          \"Energy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"need_or_resource\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"resource\",\n          \"need\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "disaster_tweets.head(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFarHGU2UXOt"
      },
      "source": [
        "###Extract the tweets and the respective labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiKrF0KFUboE"
      },
      "outputs": [],
      "source": [
        "#Read the tweet data and convert it to lowercase\n",
        "tweets = disaster_tweets['text'].str.lower()\n",
        "\n",
        "# this line of code removes all characters that are not letters or numbers from each tweet and replaces them with a space\n",
        "tweets = tweets.apply(lambda x: re.sub(r'[^a-zA-Z0-9]+', ' ',x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BluaQntKUdVx"
      },
      "outputs": [],
      "source": [
        "#Extract the labels from the csv\n",
        "tweet_labels = disaster_tweets['category']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO387hafT5H2"
      },
      "source": [
        "###Split the data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMyzuSELT_Fg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "4d18c105-fc11-4e1c-fef9-aa1719aa26db"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains NaN",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2894793118.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Split the Data into Training and Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2403\u001b[0m                 \u001b[0mUserWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m             )\n\u001b[0;32m-> 2405\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_array_api\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# We need only consider float arrays, hence can early return for all else.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
          ]
        }
      ],
      "source": [
        "#Split the Data into Training and Testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets, tweet_labels, test_size=0.2, random_state=1,stratify = tweet_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQTQZlkBTuKW"
      },
      "source": [
        "###Load the GLoVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tob5aXKeRnAe",
        "outputId": "ecf2ff93-e6a5-4ad6-f603-0eb9b9ea749b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.40MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:32<00:00, 12171.78it/s]\n"
          ]
        }
      ],
      "source": [
        "VEC_SIZE = 300\n",
        "glove = GloVe(name='6B', dim=VEC_SIZE)\n",
        "\n",
        "# Returns word vector for word if it exists, else return None.\n",
        "def get_word_vector(word):\n",
        "    try:\n",
        "      return glove.vectors[glove.stoi[word.lower()]].numpy()\n",
        "    except KeyError:\n",
        "      return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHQD9FN4Sh6S"
      },
      "source": [
        "We've included a handy helper function which retrieves the word vector for a word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyAdf1dESmcW"
      },
      "source": [
        "##Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qibHFjzeSsO1"
      },
      "source": [
        "Let's retrieve the word vector for \"good\" using the above get_word_vector function (~30 seconds)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kamIu6s4Sg2w",
        "outputId": "64420a39-1c0e-4b62-e92f-12b118253fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of good vector: (300,)\n",
            "[-1.3602e-01 -1.1594e-01 -1.7078e-02 -2.9256e-01  1.6149e-02  8.6472e-02\n",
            "  1.5759e-03  3.4395e-01  2.1661e-01 -2.1366e+00  3.5278e-01 -2.3909e-01\n",
            " -2.2174e-01  3.6413e-01 -4.5021e-01  1.2104e-01 -1.5596e-01 -3.8906e-02\n",
            " -2.9419e-03  1.6009e-02 -1.1620e-01  3.8680e-01  3.5109e-01  9.7426e-02\n",
            " -1.2425e-02 -1.7864e-01 -2.3259e-01 -2.6960e-01  4.1083e-02 -7.6194e-02\n",
            " -2.3362e-01  2.0919e-01 -2.7264e-01  5.4967e-02 -1.8055e+00  5.6348e-01\n",
            " -1.2778e-01  2.3147e-01 -5.8820e-03 -2.6630e-01  4.1187e-01 -3.7162e-01\n",
            " -2.0600e-01 -1.9619e-01 -4.3945e-03  1.2513e-01  4.6638e-01  4.5159e-01\n",
            " -1.5000e-01  5.9589e-03  5.9070e-02 -4.1440e-01  6.1035e-02 -2.1117e-01\n",
            " -4.0988e-01  5.6393e-01  2.3021e-01  2.7240e-01  4.9364e-02  1.4239e-01\n",
            "  4.1841e-01 -1.3983e-01  3.4826e-01 -1.0745e-01 -2.5002e-01 -3.2554e-01\n",
            "  3.3343e-01 -3.5617e-01  2.0442e-01  1.4439e-01 -1.2686e-01 -7.7273e-02\n",
            " -1.9667e-01  1.0759e-01 -1.1860e-01 -2.5083e-01  1.4205e-02  2.7251e-01\n",
            " -2.3707e-01 -2.3545e-01 -1.5887e-01  1.3151e-01  6.9564e-01  2.2766e-01\n",
            "  1.8526e-01  1.5743e-01 -1.5018e-01 -1.8177e-01 -3.3527e-02 -3.3092e-01\n",
            " -2.5205e-01  5.0913e-01 -2.5607e-01 -5.3686e-01  1.3397e-01  6.7046e-02\n",
            " -9.4473e-02 -2.2270e-01 -3.1469e-01  8.5932e-02 -4.3032e-02 -2.5821e-01\n",
            " -9.5062e-02 -1.8497e-01  5.8890e-02  1.8972e-01 -1.7366e-01  2.5263e-01\n",
            " -5.4361e-01 -3.7248e-01 -4.6661e-02 -4.1657e-01 -1.7549e-03 -4.8404e-01\n",
            "  4.2090e-01 -1.2749e-03  9.4697e-03 -1.3380e-01  7.2351e-02 -1.2096e-01\n",
            " -7.2870e-02 -1.8333e-01  3.9652e-01  1.1329e-01 -6.3029e-02 -1.9702e-03\n",
            "  4.2848e-01  3.1790e-01 -1.5079e-01  2.0405e-01  2.1828e-01  2.6067e-02\n",
            "  4.3621e-02  3.9224e-03 -2.6629e-01 -2.8312e-01  5.0497e-02 -1.8993e-01\n",
            "  1.8996e-01  2.9517e-01 -1.1566e-01  4.0967e-01  2.2221e-01 -3.9778e-01\n",
            " -3.3177e-01 -1.3884e-01 -1.6829e-01 -2.0355e-01 -2.7687e-01 -1.1087e-01\n",
            " -6.7466e-01 -1.8108e-01  1.8512e-01 -9.4616e-02  1.7856e-01 -6.6997e-02\n",
            "  1.1379e-01 -9.3380e-02  5.6860e-01 -1.3365e-01  3.4636e-01 -4.1953e-01\n",
            "  1.7547e-01 -2.4277e-02 -1.2441e-01  9.2129e-02 -1.6702e-01 -1.4285e-01\n",
            "  3.1646e-01  3.0337e-01  1.4840e-01 -6.7837e-03 -1.0509e+00  2.2329e-01\n",
            "  7.5211e-02  4.4379e-02 -8.5929e-02 -1.1806e-01 -1.6632e-01 -7.8650e-02\n",
            "  2.6374e-01 -2.2052e-01  4.5582e-01 -1.5291e-01  6.2617e-02 -1.5588e-01\n",
            "  8.2398e-02 -6.8462e-02 -2.4569e-01  2.3439e-01 -3.8633e-01  2.4835e-01\n",
            "  2.5334e-01 -2.1189e-01  4.1494e-03 -4.3762e-01 -1.3426e-01 -2.4583e-01\n",
            "  1.4213e-01 -3.3973e-01  1.4643e+00  1.6414e-01  2.2135e-01  7.4099e-03\n",
            " -5.5141e-02 -2.7403e-02  3.2928e-02  1.4289e-01 -1.0049e-01 -2.2066e-01\n",
            " -3.0380e-01  6.0624e-02 -1.2408e-01 -5.4114e-01  2.4374e-01  8.0903e-02\n",
            " -7.8264e-02  8.0091e-02  9.8551e-03 -2.3077e-01  1.6006e-01  6.4075e-02\n",
            " -4.1613e-01  2.0494e-01 -1.8681e-01  3.5367e-02  2.1759e-01 -8.7823e-02\n",
            "  3.5452e-01  1.9578e-01 -1.5127e-01 -1.0545e-01  3.5650e-01 -3.8677e-01\n",
            " -6.3172e-02  3.1534e-01 -1.5887e-01 -3.1267e-01 -1.7893e-01  4.1952e-01\n",
            "  2.3261e-01  2.0943e-01  2.7013e-02  1.7388e-02 -5.9857e-01 -1.9622e-01\n",
            " -2.3672e-01  3.0032e-01  4.6926e-02 -8.5768e-02  3.6539e-01 -5.2476e-01\n",
            " -1.3618e-01  1.0868e-01  4.6307e-01  3.8502e-01  7.6317e-04 -3.8196e-01\n",
            "  7.9772e-02 -4.1744e-02  4.7625e-02 -4.1018e-02  1.7601e-01  2.4893e-01\n",
            " -1.0753e-01  3.1935e-01 -1.2762e-01 -3.5059e-01  3.5689e-04  9.3515e-03\n",
            " -8.8616e-02 -3.2785e-01  9.2063e-02 -6.1405e-02  2.9053e-01  2.2404e-02\n",
            " -1.6879e+00  2.6712e-01  3.3419e-01 -5.2533e-02 -1.9741e-01  1.3709e-01\n",
            " -5.4288e-02  5.6423e-01  1.9384e-01  1.7229e-01  2.9025e-01 -1.6124e-01\n",
            "  5.9489e-02 -3.1884e-01 -2.8343e-01  6.4321e-02 -4.1589e-01 -7.0528e-02\n",
            "  1.2410e-02 -4.0208e-01 -2.4963e-01 -3.3760e-01  7.0098e-02  2.4642e-01]\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE ###\n",
        "good_vector = get_word_vector(\"good\")\n",
        "### END CODE HERE ###\n",
        "\n",
        "print('Shape of good vector:', good_vector.shape)\n",
        "print(good_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeB-ADYzS-P4"
      },
      "source": [
        "Well not much to see here–each word vector is a vector of 300 numbers, and it's hard to interpret them from looking at the numbers. Remember that the important property of word vectors is that words with similar meaning have similar word vectors. The magic happens when we compare word vectors.\n",
        "\n",
        "Below, we have set up a demo where we compare the word vectors for two words using a comparison metric known as cosine similarity. Intuitively, cosine similarity measures the extent to which two vectors point in the same direction. You might be familiar with the fact that the cosine similarity between two vectors is the same as the cosine of the angle between the two vectors–ranging between -1 and 1. -1 means that two vectors are facing opposite directions, 0 means that they are perpendicular, and 1 means that they are facing the same direction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTIpLdgsTJJD"
      },
      "source": [
        "##Instructor-Led Discussion: Comparing Word Similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZubOH_J9TOLz"
      },
      "source": [
        "Try running the below to compare the vectors for \"good\" and \"great\", and then try other words, like \"planet\". What do you notice that's expected and unexpected? Play around for a couple of minutes then discuss as a class.\n",
        "\n",
        "Note that the demo runs automatically when you change either word1 or word2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To_1Uy8_TCZ1",
        "outputId": "04a80782-78b7-4e40-9685-bfeaf702a09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word 1: cat\n",
            "Word 2: potion\n",
            "\n",
            "Cosine similarity: 0.08579734\n"
          ]
        }
      ],
      "source": [
        "#@title Word Similarity { run: \"auto\", display-mode: \"both\" }\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "  return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "word1 = \"cat\" #@param {type:\"string\"}\n",
        "word2 = \"potion\" #@param {type:\"string\"}\n",
        "\n",
        "print('Word 1:', word1)\n",
        "print('Word 2:', word2)\n",
        "\n",
        "def cosine_similarity_of_words(word1, word2):\n",
        "  vec1 = get_word_vector(word1)\n",
        "  vec2 = get_word_vector(word2)\n",
        "\n",
        "  if vec1 is None:\n",
        "    print(word1, 'is not a valid word. Try another.')\n",
        "  if vec2 is None:\n",
        "    print(word2, 'is not a valid word. Try another.')\n",
        "  if vec1 is None or vec2 is None:\n",
        "    return None\n",
        "\n",
        "  return cosine_similarity(vec1, vec2)\n",
        "\n",
        "\n",
        "print('\\nCosine similarity:', cosine_similarity_of_words(word1, word2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPgrLPmTXSY"
      },
      "source": [
        "We can see that word embeddings appear to capture the meaning of different words–when two words are similar, the cosine similarity score is higher, and when two words are dissimilar, the cosine similarity score is lower.\n",
        "\n",
        "Word vectors are created by going over a large body of text (the vectors you are using were trained on Wikipedia in part) and noticing which words tend to occur near each-other. If word A tends to co-occur with similar words as word B, then the word vectors for words A and B are mathematically constrained to be similar. If you want to learn more about an algorithm for training word vectors, see this [helpful introduction to word2vec](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa).\n",
        "\n",
        "Given word vectors that represent the meaning of words, what can we do with this? We can add word vectors to our feature vector, but which do we choose? It turns out that a solid approach is just to average the word vectors for all the words in the description. Averaging word vectors produces a natural way to produce vectors for sentences and other collections of words, and this is the approach we will use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjudMdP2TfrG"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "We want to write a function that takes a list of descriptions and turns it into an array containing the average GloVe vector for each description. **Understand the code below and then increment found_words and add vec to X[i].**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JnBXudzmTQgH"
      },
      "outputs": [],
      "source": [
        "def glove_transform_data_descriptions(descriptions):\n",
        "    X = np.zeros((len(descriptions), VEC_SIZE))\n",
        "    for i, description in enumerate(descriptions):\n",
        "        found_words = 0.0\n",
        "        description = description.strip()\n",
        "        for word in description.split():\n",
        "            vec = get_word_vector(word)\n",
        "            if vec is not None:\n",
        "              found_words += 1\n",
        "              X[i] += vec\n",
        "                ### YOUR CODE HERE ###\n",
        "                # Increment found_words and add vec to X[i].\n",
        "\n",
        "\n",
        "                ### END CODE HERE ###\n",
        "        # We divide the sum by the number of words added, so we have the\n",
        "        # average word vector.\n",
        "        if found_words > 0:\n",
        "            X[i] /= found_words\n",
        "\n",
        "    return X\n",
        "\n",
        "glove_train_X = glove_transform_data_descriptions(X_train)\n",
        "glove_train_y = [label for label in y_train]\n",
        "\n",
        "glove_test_X = glove_transform_data_descriptions(X_test)\n",
        "glove_test_y = [label for label in y_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrlEEN6pXT1S"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Then, we can evaluate our approach as we have in the past. As before, fill in the code for fitting and evaluation (~8 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y0z-uQ6XS7z"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va6CVv0SoEOt"
      },
      "source": [
        "###Exercise(Discussion): Why do you think the accuracy didn't change much even though we introduced word embeddings as our features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYccPzP4Ykym"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test,glove_test_y_pred, target_names=['Energy', 'Food', 'Medical', 'None', 'Water']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZOKzdGObUKh"
      },
      "outputs": [],
      "source": [
        "#@title Helper Function-Confusion Matrix\n",
        "'''\n",
        "Plots the confusion Matrix and saves it\n",
        "'''\n",
        "def plot_confusion_matrix(y_true,y_predicted):\n",
        "  cm = metrics.confusion_matrix(y_true, y_predicted)\n",
        "  print (\"Plotting the Confusion Matrix\")\n",
        "  labels = ['Energy', 'Food', 'Medical', 'None', 'Water']\n",
        "  df_cm = pd.DataFrame(cm,index =labels,columns = labels)\n",
        "  fig = plt.figure()\n",
        "  res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "  plt.yticks([0.5,1.5,2.5,3.5,4.5], labels,va='center')\n",
        "  plt.title('Confusion Matrix - TestData')\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZa0F_7qbZt0"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_test,glove_test_y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNLOH21heC3G"
      },
      "source": [
        "###Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8zuQKqYeTNE"
      },
      "source": [
        "*Let's see how our classifier did! We will train our classifier on 80% of the dataset and then test it on 20%. This is called a train-test split and is usually done to evaluate models.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C1qWUIs_tnee"
      },
      "outputs": [],
      "source": [
        "#@title Get the list of incorrect tweets\n",
        "pd.set_option('max_colwidth', 500)\n",
        "incorrect_tweets = []\n",
        "incorrect_y_test = []\n",
        "incorrect_y_pred = []\n",
        "for (t,x,y) in zip(X_test,y_test,glove_test_y_pred):\n",
        "  if x != y:\n",
        "    incorrect_tweets.append(t)\n",
        "    incorrect_y_test.append(x)\n",
        "    incorrect_y_pred.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxglAdpaeSf4"
      },
      "outputs": [],
      "source": [
        "table=pd.DataFrame([incorrect_tweets,incorrect_y_pred,incorrect_y_test]).transpose()\n",
        "table.columns = ['Tweet', 'Predicted Category', 'True Category']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGJpRZjOeE29"
      },
      "outputs": [],
      "source": [
        "table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOal-XMkJ2R"
      },
      "source": [
        "###Exercise(Discussion): Can you figure out why some of these tweets were incorrectly classified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHKXjfBKvDjh"
      },
      "source": [
        "###Visualizing Word Vectors with t-SNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmfV7ujlksjg"
      },
      "source": [
        "We will plot the words using the word embeddings in this section to derive relationships based on the context of the tweets. Learn more about t-SNE [here.](https://blog.clairvoyantsoft.com/mlmuse-visualisation-of-high-dimensional-data-using-t-sne-ac6264316d7f)\n",
        "\n",
        "A t-SNE demo is also available [here!](https://distill.pub/2016/misread-tsne/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6xSUQoDwWwU"
      },
      "outputs": [],
      "source": [
        "#@title Helper Function to Visualize the Embeddings\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def clean(text):\n",
        "    \"\"\"Remove posting header, split by sentences and words, keep only letters\"\"\"\n",
        "    lines = re.split('[?!.:]\\s', re.sub('^.*Lines: \\d+', '', re.sub('\\n', ' ', text)))\n",
        "    return [re.sub('[^a-zA-Z]', ' ', line).lower().split() for line in lines]\n",
        "\n",
        "sentences = [line for text in tweets for line in clean(text)]\n",
        "\n",
        "#min-count variable helps us eliminate the words which rarely occur!\n",
        "model = Word2Vec(sentences, workers=4, vector_size=100, min_count=30, window=10, sample=1e-3)\n",
        "\n",
        "\n",
        "def tsne_plot(model):\n",
        "    \"Creates and TSNE model and plots it\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    for word in model.wv.key_to_index:\n",
        "        tokens.append(model.wv.get_vector(word, norm=True))\n",
        "        labels.append(word)\n",
        "\n",
        "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(np.array(tokens))\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i],y[i])\n",
        "        plt.annotate(labels[i],\n",
        "                     xy=(x[i], y[i]),\n",
        "                     xytext=(5, 2),\n",
        "                     textcoords='offset points',\n",
        "                     ha='right',\n",
        "                     va='bottom')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7FmjhbkZawM"
      },
      "outputs": [],
      "source": [
        "tsne_plot(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViStd1wJnpQO"
      },
      "source": [
        "###Exercise(Discussion): Do you notice that similar words are placed close by?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNkVVIP4n0mz"
      },
      "source": [
        "#Finish!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}